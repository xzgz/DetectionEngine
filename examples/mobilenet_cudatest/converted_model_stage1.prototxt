name: "converted_model_stage1"
input: "0"
input_shape {
  dim: 1
  dim: 3
  dim: 512
  dim: 512
}
layer {
  name: "Convolution_0"
  type: "Convolution"
  bottom: "0"
  top: "335"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "BatchNorm_1"
  type: "BatchNorm"
  bottom: "335"
  top: "BatchNorm1"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "336"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_2"
  type: "ReLU"
  bottom: "336"
  top: "337"
}
layer {
  name: "Convolution_3"
  type: "Convolution"
  bottom: "337"
  top: "338"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 32
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_4"
  type: "BatchNorm"
  bottom: "338"
  top: "BatchNorm4"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_4"
  type: "Scale"
  bottom: "BatchNorm4"
  top: "339"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_5"
  type: "ReLU"
  bottom: "339"
  top: "340"
}
layer {
  name: "Convolution_6"
  type: "Convolution"
  bottom: "340"
  top: "341"
  convolution_param {
    num_output: 16
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_7"
  type: "BatchNorm"
  bottom: "341"
  top: "BatchNorm7"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_7"
  type: "Scale"
  bottom: "BatchNorm7"
  top: "342"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_8"
  type: "Convolution"
  bottom: "342"
  top: "343"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_9"
  type: "BatchNorm"
  bottom: "343"
  top: "BatchNorm9"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_9"
  type: "Scale"
  bottom: "BatchNorm9"
  top: "344"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_10"
  type: "ReLU"
  bottom: "344"
  top: "345"
}
layer {
  name: "Convolution_11"
  type: "Convolution"
  bottom: "345"
  top: "346"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 96
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "BatchNorm_12"
  type: "BatchNorm"
  bottom: "346"
  top: "BatchNorm12"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_12"
  type: "Scale"
  bottom: "BatchNorm12"
  top: "347"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_13"
  type: "ReLU"
  bottom: "347"
  top: "348"
}
layer {
  name: "Convolution_14"
  type: "Convolution"
  bottom: "348"
  top: "349"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_15"
  type: "BatchNorm"
  bottom: "349"
  top: "BatchNorm15"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_15"
  type: "Scale"
  bottom: "BatchNorm15"
  top: "350"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_16"
  type: "Convolution"
  bottom: "350"
  top: "351"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_17"
  type: "BatchNorm"
  bottom: "351"
  top: "BatchNorm17"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_17"
  type: "Scale"
  bottom: "BatchNorm17"
  top: "352"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_18"
  type: "ReLU"
  bottom: "352"
  top: "353"
}
layer {
  name: "Convolution_19"
  type: "Convolution"
  bottom: "353"
  top: "354"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_20"
  type: "BatchNorm"
  bottom: "354"
  top: "BatchNorm20"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_20"
  type: "Scale"
  bottom: "BatchNorm20"
  top: "355"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_21"
  type: "ReLU"
  bottom: "355"
  top: "356"
}
layer {
  name: "Convolution_22"
  type: "Convolution"
  bottom: "356"
  top: "357"
  convolution_param {
    num_output: 24
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_23"
  type: "BatchNorm"
  bottom: "357"
  top: "BatchNorm23"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_23"
  type: "Scale"
  bottom: "BatchNorm23"
  top: "358"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_24"
  type: "Eltwise"
  bottom: "350"
  bottom: "358"
  top: "359"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_25"
  type: "Convolution"
  bottom: "359"
  top: "360"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_26"
  type: "BatchNorm"
  bottom: "360"
  top: "BatchNorm26"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_26"
  type: "Scale"
  bottom: "BatchNorm26"
  top: "361"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_27"
  type: "ReLU"
  bottom: "361"
  top: "362"
}
layer {
  name: "Convolution_28"
  type: "Convolution"
  bottom: "362"
  top: "363"
  convolution_param {
    num_output: 144
    bias_term: false
    group: 144
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "BatchNorm_29"
  type: "BatchNorm"
  bottom: "363"
  top: "BatchNorm29"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_29"
  type: "Scale"
  bottom: "BatchNorm29"
  top: "364"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_30"
  type: "ReLU"
  bottom: "364"
  top: "365"
}
layer {
  name: "Convolution_31"
  type: "Convolution"
  bottom: "365"
  top: "366"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_32"
  type: "BatchNorm"
  bottom: "366"
  top: "BatchNorm32"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_32"
  type: "Scale"
  bottom: "BatchNorm32"
  top: "367"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_33"
  type: "Convolution"
  bottom: "367"
  top: "368"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_34"
  type: "BatchNorm"
  bottom: "368"
  top: "BatchNorm34"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_34"
  type: "Scale"
  bottom: "BatchNorm34"
  top: "369"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_35"
  type: "ReLU"
  bottom: "369"
  top: "370"
}
layer {
  name: "Convolution_36"
  type: "Convolution"
  bottom: "370"
  top: "371"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_37"
  type: "BatchNorm"
  bottom: "371"
  top: "BatchNorm37"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_37"
  type: "Scale"
  bottom: "BatchNorm37"
  top: "372"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_38"
  type: "ReLU"
  bottom: "372"
  top: "373"
}
layer {
  name: "Convolution_39"
  type: "Convolution"
  bottom: "373"
  top: "374"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_40"
  type: "BatchNorm"
  bottom: "374"
  top: "BatchNorm40"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_40"
  type: "Scale"
  bottom: "BatchNorm40"
  top: "375"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_41"
  type: "Eltwise"
  bottom: "367"
  bottom: "375"
  top: "376"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_42"
  type: "Convolution"
  bottom: "376"
  top: "377"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_43"
  type: "BatchNorm"
  bottom: "377"
  top: "BatchNorm43"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_43"
  type: "Scale"
  bottom: "BatchNorm43"
  top: "378"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_44"
  type: "ReLU"
  bottom: "378"
  top: "379"
}
layer {
  name: "Convolution_45"
  type: "Convolution"
  bottom: "379"
  top: "380"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_46"
  type: "BatchNorm"
  bottom: "380"
  top: "BatchNorm46"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_46"
  type: "Scale"
  bottom: "BatchNorm46"
  top: "381"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_47"
  type: "ReLU"
  bottom: "381"
  top: "382"
}
layer {
  name: "Convolution_48"
  type: "Convolution"
  bottom: "382"
  top: "383"
  convolution_param {
    num_output: 32
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_49"
  type: "BatchNorm"
  bottom: "383"
  top: "BatchNorm49"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_49"
  type: "Scale"
  bottom: "BatchNorm49"
  top: "384"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_50"
  type: "Eltwise"
  bottom: "376"
  bottom: "384"
  top: "385"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_51"
  type: "Convolution"
  bottom: "385"
  top: "386"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_52"
  type: "BatchNorm"
  bottom: "386"
  top: "BatchNorm52"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_52"
  type: "Scale"
  bottom: "BatchNorm52"
  top: "387"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_53"
  type: "ReLU"
  bottom: "387"
  top: "388"
}
layer {
  name: "Convolution_54"
  type: "Convolution"
  bottom: "388"
  top: "389"
  convolution_param {
    num_output: 192
    bias_term: false
    group: 192
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "BatchNorm_55"
  type: "BatchNorm"
  bottom: "389"
  top: "BatchNorm55"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_55"
  type: "Scale"
  bottom: "BatchNorm55"
  top: "390"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_56"
  type: "ReLU"
  bottom: "390"
  top: "391"
}
layer {
  name: "Convolution_57"
  type: "Convolution"
  bottom: "391"
  top: "392"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_58"
  type: "BatchNorm"
  bottom: "392"
  top: "BatchNorm58"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_58"
  type: "Scale"
  bottom: "BatchNorm58"
  top: "393"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_59"
  type: "Convolution"
  bottom: "393"
  top: "394"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_60"
  type: "BatchNorm"
  bottom: "394"
  top: "BatchNorm60"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_60"
  type: "Scale"
  bottom: "BatchNorm60"
  top: "395"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_61"
  type: "ReLU"
  bottom: "395"
  top: "396"
}
layer {
  name: "Convolution_62"
  type: "Convolution"
  bottom: "396"
  top: "397"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 384
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_63"
  type: "BatchNorm"
  bottom: "397"
  top: "BatchNorm63"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_63"
  type: "Scale"
  bottom: "BatchNorm63"
  top: "398"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_64"
  type: "ReLU"
  bottom: "398"
  top: "399"
}
layer {
  name: "Convolution_65"
  type: "Convolution"
  bottom: "399"
  top: "400"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_66"
  type: "BatchNorm"
  bottom: "400"
  top: "BatchNorm66"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_66"
  type: "Scale"
  bottom: "BatchNorm66"
  top: "401"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_67"
  type: "Eltwise"
  bottom: "393"
  bottom: "401"
  top: "402"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_68"
  type: "Convolution"
  bottom: "402"
  top: "403"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_69"
  type: "BatchNorm"
  bottom: "403"
  top: "BatchNorm69"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_69"
  type: "Scale"
  bottom: "BatchNorm69"
  top: "404"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_70"
  type: "ReLU"
  bottom: "404"
  top: "405"
}
layer {
  name: "Convolution_71"
  type: "Convolution"
  bottom: "405"
  top: "406"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 384
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_72"
  type: "BatchNorm"
  bottom: "406"
  top: "BatchNorm72"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_72"
  type: "Scale"
  bottom: "BatchNorm72"
  top: "407"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_73"
  type: "ReLU"
  bottom: "407"
  top: "408"
}
layer {
  name: "Convolution_74"
  type: "Convolution"
  bottom: "408"
  top: "409"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_75"
  type: "BatchNorm"
  bottom: "409"
  top: "BatchNorm75"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_75"
  type: "Scale"
  bottom: "BatchNorm75"
  top: "410"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_76"
  type: "Eltwise"
  bottom: "402"
  bottom: "410"
  top: "411"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_77"
  type: "Convolution"
  bottom: "411"
  top: "412"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_78"
  type: "BatchNorm"
  bottom: "412"
  top: "BatchNorm78"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_78"
  type: "Scale"
  bottom: "BatchNorm78"
  top: "413"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_79"
  type: "ReLU"
  bottom: "413"
  top: "414"
}
layer {
  name: "Convolution_80"
  type: "Convolution"
  bottom: "414"
  top: "415"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 384
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_81"
  type: "BatchNorm"
  bottom: "415"
  top: "BatchNorm81"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_81"
  type: "Scale"
  bottom: "BatchNorm81"
  top: "416"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_82"
  type: "ReLU"
  bottom: "416"
  top: "417"
}
layer {
  name: "Convolution_83"
  type: "Convolution"
  bottom: "417"
  top: "418"
  convolution_param {
    num_output: 64
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_84"
  type: "BatchNorm"
  bottom: "418"
  top: "BatchNorm84"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_84"
  type: "Scale"
  bottom: "BatchNorm84"
  top: "419"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_85"
  type: "Eltwise"
  bottom: "411"
  bottom: "419"
  top: "420"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_86"
  type: "Convolution"
  bottom: "420"
  top: "421"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_87"
  type: "BatchNorm"
  bottom: "421"
  top: "BatchNorm87"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_87"
  type: "Scale"
  bottom: "BatchNorm87"
  top: "422"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_88"
  type: "ReLU"
  bottom: "422"
  top: "423"
}
layer {
  name: "Convolution_89"
  type: "Convolution"
  bottom: "423"
  top: "424"
  convolution_param {
    num_output: 384
    bias_term: false
    group: 384
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_90"
  type: "BatchNorm"
  bottom: "424"
  top: "BatchNorm90"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_90"
  type: "Scale"
  bottom: "BatchNorm90"
  top: "425"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_91"
  type: "ReLU"
  bottom: "425"
  top: "426"
}
layer {
  name: "Convolution_92"
  type: "Convolution"
  bottom: "426"
  top: "427"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_93"
  type: "BatchNorm"
  bottom: "427"
  top: "BatchNorm93"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_93"
  type: "Scale"
  bottom: "BatchNorm93"
  top: "428"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_94"
  type: "Convolution"
  bottom: "428"
  top: "429"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_95"
  type: "BatchNorm"
  bottom: "429"
  top: "BatchNorm95"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_95"
  type: "Scale"
  bottom: "BatchNorm95"
  top: "430"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_96"
  type: "ReLU"
  bottom: "430"
  top: "431"
}
layer {
  name: "Convolution_97"
  type: "Convolution"
  bottom: "431"
  top: "432"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_98"
  type: "BatchNorm"
  bottom: "432"
  top: "BatchNorm98"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_98"
  type: "Scale"
  bottom: "BatchNorm98"
  top: "433"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_99"
  type: "ReLU"
  bottom: "433"
  top: "434"
}
layer {
  name: "Convolution_100"
  type: "Convolution"
  bottom: "434"
  top: "435"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_101"
  type: "BatchNorm"
  bottom: "435"
  top: "BatchNorm101"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_101"
  type: "Scale"
  bottom: "BatchNorm101"
  top: "436"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_102"
  type: "Eltwise"
  bottom: "428"
  bottom: "436"
  top: "437"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_103"
  type: "Convolution"
  bottom: "437"
  top: "438"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_104"
  type: "BatchNorm"
  bottom: "438"
  top: "BatchNorm104"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_104"
  type: "Scale"
  bottom: "BatchNorm104"
  top: "439"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_105"
  type: "ReLU"
  bottom: "439"
  top: "440"
}
layer {
  name: "Convolution_106"
  type: "Convolution"
  bottom: "440"
  top: "441"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_107"
  type: "BatchNorm"
  bottom: "441"
  top: "BatchNorm107"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_107"
  type: "Scale"
  bottom: "BatchNorm107"
  top: "442"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_108"
  type: "ReLU"
  bottom: "442"
  top: "443"
}
layer {
  name: "Convolution_109"
  type: "Convolution"
  bottom: "443"
  top: "444"
  convolution_param {
    num_output: 96
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_110"
  type: "BatchNorm"
  bottom: "444"
  top: "BatchNorm110"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_110"
  type: "Scale"
  bottom: "BatchNorm110"
  top: "445"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_111"
  type: "Eltwise"
  bottom: "437"
  bottom: "445"
  top: "446"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_112"
  type: "Convolution"
  bottom: "446"
  top: "447"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_113"
  type: "BatchNorm"
  bottom: "447"
  top: "BatchNorm113"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_113"
  type: "Scale"
  bottom: "BatchNorm113"
  top: "448"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_114"
  type: "ReLU"
  bottom: "448"
  top: "449"
}
layer {
  name: "Convolution_115"
  type: "Convolution"
  bottom: "449"
  top: "450"
  convolution_param {
    num_output: 576
    bias_term: false
    group: 576
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "BatchNorm_116"
  type: "BatchNorm"
  bottom: "450"
  top: "BatchNorm116"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_116"
  type: "Scale"
  bottom: "BatchNorm116"
  top: "451"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_117"
  type: "ReLU"
  bottom: "451"
  top: "452"
}
layer {
  name: "Convolution_118"
  type: "Convolution"
  bottom: "452"
  top: "453"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_119"
  type: "BatchNorm"
  bottom: "453"
  top: "BatchNorm119"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_119"
  type: "Scale"
  bottom: "BatchNorm119"
  top: "454"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_120"
  type: "Convolution"
  bottom: "454"
  top: "455"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_121"
  type: "BatchNorm"
  bottom: "455"
  top: "BatchNorm121"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_121"
  type: "Scale"
  bottom: "BatchNorm121"
  top: "456"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_122"
  type: "ReLU"
  bottom: "456"
  top: "457"
}
layer {
  name: "Convolution_123"
  type: "Convolution"
  bottom: "457"
  top: "458"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 960
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_124"
  type: "BatchNorm"
  bottom: "458"
  top: "BatchNorm124"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_124"
  type: "Scale"
  bottom: "BatchNorm124"
  top: "459"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_125"
  type: "ReLU"
  bottom: "459"
  top: "460"
}
layer {
  name: "Convolution_126"
  type: "Convolution"
  bottom: "460"
  top: "461"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_127"
  type: "BatchNorm"
  bottom: "461"
  top: "BatchNorm127"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_127"
  type: "Scale"
  bottom: "BatchNorm127"
  top: "462"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_128"
  type: "Eltwise"
  bottom: "454"
  bottom: "462"
  top: "463"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_129"
  type: "Convolution"
  bottom: "463"
  top: "464"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_130"
  type: "BatchNorm"
  bottom: "464"
  top: "BatchNorm130"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_130"
  type: "Scale"
  bottom: "BatchNorm130"
  top: "465"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_131"
  type: "ReLU"
  bottom: "465"
  top: "466"
}
layer {
  name: "Convolution_132"
  type: "Convolution"
  bottom: "466"
  top: "467"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 960
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_133"
  type: "BatchNorm"
  bottom: "467"
  top: "BatchNorm133"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_133"
  type: "Scale"
  bottom: "BatchNorm133"
  top: "468"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_134"
  type: "ReLU"
  bottom: "468"
  top: "469"
}
layer {
  name: "Convolution_135"
  type: "Convolution"
  bottom: "469"
  top: "470"
  convolution_param {
    num_output: 160
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_136"
  type: "BatchNorm"
  bottom: "470"
  top: "BatchNorm136"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_136"
  type: "Scale"
  bottom: "BatchNorm136"
  top: "471"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise_137"
  type: "Eltwise"
  bottom: "463"
  bottom: "471"
  top: "472"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_138"
  type: "Convolution"
  bottom: "472"
  top: "473"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_139"
  type: "BatchNorm"
  bottom: "473"
  top: "BatchNorm139"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_139"
  type: "Scale"
  bottom: "BatchNorm139"
  top: "474"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_140"
  type: "ReLU"
  bottom: "474"
  top: "475"
}
layer {
  name: "Convolution_141"
  type: "Convolution"
  bottom: "475"
  top: "476"
  convolution_param {
    num_output: 960
    bias_term: false
    group: 960
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_142"
  type: "BatchNorm"
  bottom: "476"
  top: "BatchNorm142"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_142"
  type: "Scale"
  bottom: "BatchNorm142"
  top: "477"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU_143"
  type: "ReLU"
  bottom: "477"
  top: "478"
}
layer {
  name: "Convolution_144"
  type: "Convolution"
  bottom: "478"
  top: "479"
  convolution_param {
    num_output: 320
    bias_term: false
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "BatchNorm_145"
  type: "BatchNorm"
  bottom: "479"
  top: "BatchNorm145"
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 1.0
    eps: 9.999999747378752e-06
  }
}
layer {
  name: "Scale_145"
  type: "Scale"
  bottom: "BatchNorm145"
  top: "480"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution_146"
  type: "Convolution"
  bottom: "359"
  top: "481"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_147"
  type: "ReLU"
  bottom: "481"
  top: "482"
}
layer {
  name: "Convolution_148"
  type: "Convolution"
  bottom: "385"
  top: "483"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_149"
  type: "ReLU"
  bottom: "483"
  top: "484"
}
layer {
  name: "Convolution_150"
  type: "Convolution"
  bottom: "446"
  top: "485"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_151"
  type: "ReLU"
  bottom: "485"
  top: "486"
}
layer {
  name: "Convolution_152"
  type: "Convolution"
  bottom: "480"
  top: "487"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_153"
  type: "ReLU"
  bottom: "487"
  top: "488"
}
layer {
  name: "Interp_154"
  type: "Interp"
  bottom: "488"
  top: "489"
  interp_param {
    scale_factor: 2.0
  }
}
layer {
  name: "Eltwise_155"
  type: "Eltwise"
  bottom: "486"
  bottom: "489"
  top: "490"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Interp_156"
  type: "Interp"
  bottom: "490"
  top: "491"
  interp_param {
    scale_factor: 2.0
  }
}
layer {
  name: "Eltwise_157"
  type: "Eltwise"
  bottom: "484"
  bottom: "491"
  top: "492"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Interp_158"
  type: "Interp"
  bottom: "492"
  top: "493"
  interp_param {
    scale_factor: 2.0
  }
}
layer {
  name: "Eltwise_159"
  type: "Eltwise"
  bottom: "482"
  bottom: "493"
  top: "494"
  eltwise_param {
    operation: SUM
    coeff: 1.0
    coeff: 1.0
  }
}
layer {
  name: "Convolution_160"
  type: "Convolution"
  bottom: "494"
  top: "495"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_161"
  type: "ReLU"
  bottom: "495"
  top: "496"
}
layer {
  name: "Convolution_162"
  type: "Convolution"
  bottom: "492"
  top: "497"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_163"
  type: "ReLU"
  bottom: "497"
  top: "498"
}
layer {
  name: "Convolution_164"
  type: "Convolution"
  bottom: "490"
  top: "499"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_165"
  type: "ReLU"
  bottom: "499"
  top: "500"
}
layer {
  name: "Convolution_166"
  type: "Convolution"
  bottom: "488"
  top: "501"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_167"
  type: "ReLU"
  bottom: "501"
  top: "502"
}
layer {
  name: "Pooling_168"
  type: "Pooling"
  bottom: "502"
  top: "503"
  pooling_param {
    pool: MAX
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
    ceil_mode: false
  }
}
layer {
  name: "Convolution_169"
  type: "Convolution"
  bottom: "496"
  top: "504"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_170"
  type: "ReLU"
  bottom: "504"
  top: "505"
}
layer {
  name: "Convolution_171"
  type: "Convolution"
  bottom: "505"
  top: "506"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_172"
  type: "Convolution"
  bottom: "505"
  top: "507"
  convolution_param {
    num_output: 12
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_173"
  type: "Convolution"
  bottom: "498"
  top: "508"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_174"
  type: "ReLU"
  bottom: "508"
  top: "509"
}
layer {
  name: "Convolution_175"
  type: "Convolution"
  bottom: "509"
  top: "510"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_176"
  type: "Convolution"
  bottom: "509"
  top: "511"
  convolution_param {
    num_output: 12
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_177"
  type: "Convolution"
  bottom: "500"
  top: "512"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_178"
  type: "ReLU"
  bottom: "512"
  top: "513"
}
layer {
  name: "Convolution_179"
  type: "Convolution"
  bottom: "513"
  top: "514"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_180"
  type: "Convolution"
  bottom: "513"
  top: "515"
  convolution_param {
    num_output: 12
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_181"
  type: "Convolution"
  bottom: "502"
  top: "516"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_182"
  type: "ReLU"
  bottom: "516"
  top: "517"
}
layer {
  name: "Convolution_183"
  type: "Convolution"
  bottom: "517"
  top: "518"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_184"
  type: "Convolution"
  bottom: "517"
  top: "519"
  convolution_param {
    num_output: 12
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_185"
  type: "Convolution"
  bottom: "503"
  top: "520"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "ReLU_186"
  type: "ReLU"
  bottom: "520"
  top: "521"
}
layer {
  name: "Convolution_187"
  type: "Convolution"
  bottom: "521"
  top: "522"
  convolution_param {
    num_output: 3
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "Convolution_188"
  type: "Convolution"
  bottom: "521"
  top: "523"
  convolution_param {
    num_output: 12
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
